{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824470b3",
   "metadata": {},
   "source": [
    "--------------------------------------------SCRIPT OVERVIEW---------------------------\n",
    "\n",
    "\n",
    "This script connects to the Community Google Sheet using the gspread API, authenticates through locally configured credentials, extracts the headers, and creates a Pandas DataFrame.\n",
    "It then loads this DataFrame into the Bronze layer of the SQL Server as a JSON payload.\n",
    "\n",
    "Additionally, the script generates essential metadata used for tracking and monitoring incremental loads.\n",
    "\n",
    "NOTE:\n",
    "--Credentials are securely stored as local environment variables,they are not shared in the repository.\n",
    "--The API fetches only the latest updates (incremental loads), ensuring minimal duplication.\n",
    "--Make sure your environment variables are properly configured before running this script, otherwise authentication will fail.\n",
    "--This script only handles the Bronze layer ingestion that means cleaning, transformations, and schema modeling occur in later stages (Silver/Gold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17066c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b05b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2105d0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#googlesheet credentials from environment variables\n",
    "\n",
    "UGASHEET_CREDENTIALS = os.getenv(\"UGASHEET_CRED_PATH\")\n",
    "SHEET_KEY = os.getenv(\"UGASHEET_KEY\")\n",
    "WORKSHEET_NAME = os.getenv(\"UGASHEET_NAME\", \"atendees\")\n",
    "DATABASE_URL = os.getenv(\"DB_URL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f376f381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# connecting to the google sheet using the credentials\n",
    "scope = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(UGASHEET_CREDENTIALS, scope)\n",
    "gc = gspread.authorize(creds) #authorize the gspread API client to read the data\n",
    "sh = gc.open_by_key(SHEET_KEY) #open the google sheet by its key\n",
    "ws = sh.worksheet(WORKSHEET_NAME) #selecting the worksheet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a41029d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, hashlib, pandas as pd, uuid\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac04285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ws.get_all_values()#get all data from the worksheet\n",
    "headers = data.pop(0)#extract the headers since the first row contains headers on the data table in the google sheet\n",
    "df = pd.DataFrame(data, columns=headers) #create a pandas dataframe from the data and headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df989603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create a unique hash for each row\n",
    "def row_hash(r):\n",
    "    rs = json.dumps(r, sort_keys=True,default=str)\n",
    "    return hashlib.sha256(rs.encode('utf-8')).hexdigest()\n",
    "\n",
    "#adding metadata columns to the dataframe\n",
    "df['ingested_at'] = datetime.utcnow() #timestamp for when the data was ingested\n",
    "df['source_sheet'] = WORKSHEET_NAME\n",
    "df['source_row'] = df.index + 2  #row number in the google sheet (adding 2 to account for header row and 0-based index)\n",
    "df['row_hash'] = df.apply(lambda r: row_hash(r.to_dict()), axis=1) #unique hash for each row\n",
    "df['ingest_batch_id'] = str(uuid.uuid4()) #generate a unique batch id for each ingestion run\n",
    "df['payload'] = df.apply(lambda r: json.dumps(r.drop(['row_hash','ingested_at','ingest_batch_id','source_sheet','source_row']).to_dict(), default=str), axis=1) #json payload of the entire row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6009ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9252059",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn: \n",
    "    for idx, row in df.iterrows():\n",
    "        exists = conn.execute(\n",
    "            text(\"SELECT 1 FROM bronze.ugacooq_raw WHERE row_hash = :row_hash\"),\n",
    "            {\"row_hash\": row['row_hash']}).fetchone()  \n",
    "            \n",
    "        if not exists:\n",
    "            conn.execute(\n",
    "                text(\"\"\"   \n",
    "                INSERT INTO bronze.ugacooq_raw (ingested_at, source_sheet, source_row, payload, row_hash, ingest_batch_id)\n",
    "                VALUES (:ingested_at, :source_sheet, :source_row, :payload, :row_hash, :ingest_batch_id)\n",
    "                \"\"\"),\n",
    "                {\n",
    "                    \"ingested_at\": row['ingested_at'],\n",
    "                    \"source_sheet\": row['source_sheet'],\n",
    "                    \"source_row\": idx + 2,  # Google Sheets rows start at 2 (header = row 1)\n",
    "                    \"payload\": row['payload'],\n",
    "                    \"row_hash\": row['row_hash'],\n",
    "                    \"ingest_batch_id\": row['ingest_batch_id']\n",
    "                }\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
